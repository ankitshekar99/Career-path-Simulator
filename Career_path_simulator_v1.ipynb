{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install PyPDF2 python-docx"
      ],
      "metadata": {
        "id": "aK3TGabAIiAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ff370a-e293-4877-d2a6-592a44495691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2 python-docx pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0GftMs0J6em",
        "outputId": "371773ed-b57f-48de-f91a-6a8cf49dd31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20250506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io, re\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "93FQ7q7tIlFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCgVrk8Vw4Cs",
        "outputId": "0c09f026-ace5-4d51-b933-8a290451eb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hWrote data/role_skills_specific.csv: 287\n",
            "Wrote data/demand.csv with 26 roles\n",
            "Saved transitions edges: 64\n"
          ]
        }
      ],
      "source": [
        "!pip -q install streamlit pyngrok plotly\n",
        "\n",
        "import os, random, pandas as pd\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "random.seed(9)\n",
        "\n",
        "# ----- Roles with specific, actionable skills (weights: 1–5) -----\n",
        "ROLES = {\n",
        "    \"Data Analyst\": {\n",
        "        \"SQL\":5,\"Excel\":5,\"Tableau\":4,\"Power BI\":4,\"Python\":3,\"Statistics\":3,\n",
        "        \"Data Cleaning\":4,\"Reporting\":4,\"A/B Testing\":2,\"Looker\":2,\"Snowflake\":3,\"Visualization\":4\n",
        "    },\n",
        "    \"BI Analyst\": {\n",
        "        \"SQL\":5,\"ETL\":4,\"Power BI\":5,\"Tableau\":4,\"Data Modeling\":4,\"DAX\":4,\"SSRS\":3,\"SSIS\":3,\n",
        "        \"Snowflake\":3,\"dbt\":3,\"Python\":2\n",
        "    },\n",
        "    \"Analytics Engineer\": {\n",
        "        \"SQL\":5,\"dbt\":5,\"Data Modeling\":5,\"ETL\":4,\"Snowflake\":4,\"BigQuery\":4,\"Airflow\":3,\n",
        "        \"Version Control\":3,\"Documentation\":3,\"Testing\":3\n",
        "    },\n",
        "    \"Data Scientist\": {\n",
        "        \"Python\":5,\"Pandas\":5,\"NumPy\":5,\"Statistics\":5,\"Machine Learning\":5,\"Scikit-learn\":4,\n",
        "        \"SQL\":4,\"Feature Engineering\":4,\"Model Evaluation\":4,\"Experiment Design\":3,\"TensorFlow\":3,\"PyTorch\":3\n",
        "    },\n",
        "    \"Machine Learning Engineer\": {\n",
        "        \"Python\":5,\"PyTorch\":4,\"TensorFlow\":4,\"Docker\":4,\"Kubernetes\":3,\"ML Ops\":5,\"Model Serving\":5,\n",
        "        \"FastAPI\":3,\"Airflow\":3,\"AWS\":4,\"GCP\":3,\"CI/CD\":4,\"Monitoring\":3,\"Feature Store\":3\n",
        "    },\n",
        "    \"MLOps Engineer\": {\n",
        "        \"ML Ops\":5,\"Model Serving\":5,\"Docker\":5,\"Kubernetes\":5,\"CI/CD\":4,\"Feature Store\":4,\"Experiment Tracking\":4,\n",
        "        \"Python\":3,\"Monitoring\":4,\"Grafana\":3,\"Prometheus\":3,\"AWS\":4\n",
        "    },\n",
        "    \"Data Engineer\": {\n",
        "        \"Python\":5,\"SQL\":5,\"ETL\":5,\"Airflow\":4,\"Spark\":4,\"Databricks\":4,\"AWS\":4,\"GCP\":3,\"Azure\":3,\n",
        "        \"Kafka\":3,\"dbt\":4,\"Snowflake\":4,\"Data Modeling\":4,\"S3\":3,\"Redshift\":3\n",
        "    },\n",
        "    \"Database Administrator\": {\n",
        "        \"SQL\":5,\"PostgreSQL\":4,\"MySQL\":4,\"Oracle\":4,\"Backups\":5,\"Performance Tuning\":5,\"Replication\":4,\"Security\":4,\"Shell Scripting\":3\n",
        "    },\n",
        "    \"Backend Engineer\": {\n",
        "        \"Java\":5,\"Python\":4,\"Go\":3,\"APIs\":5,\"Databases\":4,\"Docker\":4,\"Kubernetes\":3,\"AWS\":4,\n",
        "        \"Caching\":3,\"Testing\":4,\"CI/CD\":4,\"Distributed Systems\":3\n",
        "    },\n",
        "    \"Frontend Engineer\": {\n",
        "        \"JavaScript\":5,\"TypeScript\":4,\"React\":5,\"CSS\":4,\"HTML\":5,\"Next.js\":3,\"Redux\":3,\"Testing Library\":3,\"Accessibility\":3,\"UX\":3\n",
        "    },\n",
        "    \"Full Stack Engineer\": {\n",
        "        \"JavaScript\":5,\"TypeScript\":4,\"React\":5,\"Node.js\":4,\"APIs\":4,\"Databases\":4,\"Docker\":3,\"AWS\":3,\"Testing\":3,\"CI/CD\":3\n",
        "    },\n",
        "    \"Mobile Engineer (Android)\": {\n",
        "        \"Kotlin\":5,\"Java\":4,\"Android SDK\":5,\"Gradle\":3,\"REST\":4,\"SQLite\":3,\"Unit Testing\":3,\"Play Store\":3\n",
        "    },\n",
        "    \"DevOps Engineer\": {\n",
        "        \"AWS\":5,\"Terraform\":4,\"Docker\":5,\"Kubernetes\":5,\"Linux\":5,\"CI/CD\":5,\"Monitoring\":4,\"Python\":3,\"Ansible\":4,\"GitHub Actions\":3\n",
        "    },\n",
        "    \"Site Reliability Engineer\": {\n",
        "        \"Linux\":5,\"Kubernetes\":5,\"Docker\":4,\"Observability\":5,\"Incident Response\":5,\"SRE\":5,\n",
        "        \"AWS\":4,\"Capacity Planning\":4,\"Postmortems\":4,\"Automation\":4,\"Python\":3\n",
        "    },\n",
        "    \"Cloud Engineer\": {\n",
        "        \"AWS\":5,\"Azure\":4,\"GCP\":4,\"Networking\":4,\"IAM\":4,\"Terraform\":4,\"Docker\":3,\"Kubernetes\":3,\"Linux\":4,\"Bash\":3\n",
        "    },\n",
        "    \"Security Analyst\": {\n",
        "        \"SIEM (Splunk)\":5,\"Incident Response\":5,\"Threat Hunting\":4,\"Vulnerability Mgmt\":4,\"Linux\":4,\n",
        "        \"Networking\":4,\"Python\":3,\"Cloud Security\":3,\"IAM\":3,\"NIST\":3\n",
        "    },\n",
        "    \"Security Engineer\": {\n",
        "        \"Cloud Security\":5,\"IAM\":5,\"Network Security\":5,\"AppSec\":4,\"OWASP\":4,\"Burp Suite\":3,\n",
        "        \"SAST/DAST\":4,\"Python\":3,\"Kubernetes\":3,\"Terraform\":3\n",
        "    },\n",
        "    \"QA Engineer\": {\n",
        "        \"Test Automation\":5,\"Selenium\":4,\"API Testing\":4,\"Postman\":4,\"PyTest\":3,\"Java\":3,\"Python\":3,\"CI/CD\":3,\"Test Strategy\":4\n",
        "    },\n",
        "    \"SDET\": {\n",
        "        \"Test Automation\":5,\"Selenium\":4,\"Java\":4,\"Python\":3,\"CI/CD\":4,\"API Testing\":4,\"Framework Design\":4,\"TDD\":3\n",
        "    },\n",
        "    \"Product Manager\": {\n",
        "        \"Stakeholder Management\":5,\"Roadmapping\":5,\"Prioritization\":5,\"JIRA\":4,\"SQL\":3,\"A/B Testing\":3,\n",
        "        \"Analytics\":4,\"User Research\":4,\"Presentation\":4,\"PRD\":4\n",
        "    },\n",
        "    \"Product Analyst\": {\n",
        "        \"SQL\":5,\"Excel\":5,\"Tableau\":4,\"Product Analytics\":5,\"Experiment Design\":4,\"Amplitude\":4,\"Mixpanel\":4,\"A/B Testing\":4,\"Python\":2\n",
        "    },\n",
        "    \"Product Designer (UX/UI)\": {\n",
        "        \"Figma\":5,\"User Research\":5,\"Wireframing\":5,\"Prototyping\":5,\"Design Systems\":4,\"Usability Testing\":4,\"Accessibility\":4,\"Visual Design\":4\n",
        "    },\n",
        "    \"Marketing Analyst\": {\n",
        "        \"SQL\":4,\"Excel\":5,\"Google Analytics\":5,\"Looker\":3,\"Tableau\":3,\"A/B Testing\":4,\"Attribution\":4,\"Facebook Ads\":3,\"Python\":2\n",
        "    },\n",
        "    \"Financial Analyst\": {\n",
        "        \"Excel\":5,\"Financial Modeling\":5,\"Forecasting\":4,\"SQL\":3,\"PowerPoint\":4,\"Accounting\":4,\"Reporting\":4,\"Budgeting\":4\n",
        "    },\n",
        "    \"Business Analyst\": {\n",
        "        \"Excel\":5,\"Stakeholder Management\":5,\"Requirements Gathering\":5,\"SQL\":3,\"Process Mapping\":4,\"Documentation\":4,\"Presentation\":4,\"JIRA\":3,\"KPIs\":4\n",
        "    },\n",
        "    \"Solutions Architect\": {\n",
        "        \"AWS\":5,\"Architecture\":5,\"APIs\":4,\"Databases\":4,\"Security\":4,\"Networking\":4,\"Pre-sales\":4,\"Diagrams\":4,\"Terraform\":3,\"Kubernetes\":3\n",
        "    }\n",
        "}\n",
        "\n",
        "EXTRA_POOL = [\n",
        "    \"Git\",\"Confluence\",\"Matplotlib\",\"Seaborn\",\"Plotly\",\"Snowflake\",\"BigQuery\",\"S3\",\"Athena\",\"Presto\",\n",
        "    \"Hive\",\"Airflow\",\"dbt\",\"Fivetran\",\"Looker\",\"Notion\",\"Linear\",\"Grafana\",\"Prometheus\",\"PowerPoint\"\n",
        "]\n",
        "\n",
        "def expand(skills: dict, max_noise=2):\n",
        "    out = skills.copy()\n",
        "    for s in random.sample(EXTRA_POOL, k=random.randint(0, max_noise)):\n",
        "        out.setdefault(s, random.choice([2,3]))\n",
        "    for k in list(out.keys()):\n",
        "        out[k] = int(max(1, min(5, out[k])))\n",
        "    return out\n",
        "\n",
        "rows=[]\n",
        "for role, skills in ROLES.items():\n",
        "    s = expand(skills)\n",
        "    rows += [(role, sk, wt) for sk, wt in s.items()]\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"role\",\"skill\",\"weight\"]).drop_duplicates()\n",
        "df.to_csv(\"data/role_skills_specific.csv\", index=False)\n",
        "\n",
        "# Synthetic demand (0..1)\n",
        "dem = [(role, round(random.uniform(0.35, 0.95), 2)) for role in ROLES]\n",
        "pd.DataFrame(dem, columns=[\"role\",\"demand_pct\"]).to_csv(\"data/demand.csv\", index=False)\n",
        "\n",
        "print(\"Wrote data/role_skills_specific.csv:\", len(df))\n",
        "print(\"Wrote data/demand.csv with\", len(ROLES), \"roles\")\n",
        "\n",
        "# Generate transitions (sparse-ish, we still add universal fallback later)\n",
        "rs = pd.read_csv(\"data/role_skills_specific.csv\")\n",
        "role2skills = {r: {row[\"skill\"]: int(row[\"weight\"]) for _, row in g.iterrows()}\n",
        "               for r, g in rs.groupby(\"role\")}\n",
        "roles = list(role2skills.keys())\n",
        "\n",
        "def weighted_jaccard(a:dict,b:dict)->float:\n",
        "    keys = set(a)|set(b)\n",
        "    num = sum(min(a.get(k,0), b.get(k,0)) for k in keys)\n",
        "    den = sum(max(a.get(k,0), b.get(k,0)) for k in keys)\n",
        "    return num/den if den else 0.0\n",
        "\n",
        "K=10; MIN_SIM=0.15\n",
        "edges=[]\n",
        "for r in roles:\n",
        "    sims=[(q, weighted_jaccard(role2skills[r], role2skills[q])) for q in roles if q!=r]\n",
        "    sims=[(q,s) for q,s in sims if s>=MIN_SIM]\n",
        "    sims.sort(key=lambda x:x[1], reverse=True)\n",
        "    for q,s in sims[:K]:\n",
        "        edges.append((r,q,round(s,4)))\n",
        "\n",
        "pd.DataFrame(edges, columns=[\"src\",\"dst\",\"sim\"]).to_csv(\"data/transitions.csv\", index=False)\n",
        "print(\"Saved transitions edges:\", len(edges))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p utils"
      ],
      "metadata": {
        "id": "YaPXCqMCw-Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils/__init__.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import io\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "\n",
        "# -------------------- Data --------------------\n",
        "RS  = pd.read_csv(\"data/role_skills_specific.csv\")   # role, skill, weight\n",
        "EDG = pd.read_csv(\"data/transitions.csv\")            # src, dst, sim\n",
        "try:\n",
        "    DEM = pd.read_csv(\"data/demand.csv\").set_index(\"role\")[\"demand_pct\"].to_dict()\n",
        "except Exception:\n",
        "    DEM = {}\n",
        "\n",
        "ROLES  = sorted(RS[\"role\"].unique().tolist())\n",
        "SKILLS = sorted(RS[\"skill\"].unique().tolist())\n",
        "\n",
        "# Pre-compute role -> {skill:weight}\n",
        "_ROLE2SK: Dict[str, Dict[str, int]] = {\n",
        "    r: {row.skill: int(row.weight) for row in g.itertuples(index=False)}\n",
        "    for r, g in RS.groupby(\"role\")\n",
        "}\n",
        "\n",
        "# -------------------- Core helpers --------------------\n",
        "def role_skills(role: str) -> Dict[str, int]:\n",
        "    g = RS[RS[\"role\"] == role][[\"skill\", \"weight\"]]\n",
        "    return dict(zip(g[\"skill\"], g[\"weight\"]))\n",
        "\n",
        "def weighted_jaccard(a: Dict[str,int], b: Dict[str,int]) -> float:\n",
        "    keys = set(a) | set(b)\n",
        "    num  = sum(min(a.get(k,0), b.get(k,0)) for k in keys)\n",
        "    den  = sum(max(a.get(k,0), b.get(k,0)) for k in keys)\n",
        "    return (num/den) if den else 0.0\n",
        "\n",
        "def role_similarity(role_a: str, role_b: str) -> float:\n",
        "    return weighted_jaccard(_ROLE2SK.get(role_a, {}), _ROLE2SK.get(role_b, {}))\n",
        "\n",
        "def edge_score(src: str, dst: str, sim: float, lam: float = 0.3) -> float:\n",
        "    return float(sim) * (1 + lam * float(DEM.get(dst, 0.0)))\n",
        "\n",
        "# -------------------- Static graph APIs --------------------\n",
        "def neighbors(role: str, topn: int = 10, lam: float = 0.3, target: Optional[str] = None):\n",
        "    df = EDG[EDG[\"src\"] == role].copy()\n",
        "    if not df.empty:\n",
        "        df[\"score\"] = df.apply(lambda r: edge_score(r[\"src\"], r[\"dst\"], r[\"sim\"], lam), axis=1)\n",
        "        return df.sort_values(\"score\", ascending=False).head(topn)[[\"dst\",\"score\",\"sim\"]]\n",
        "    dyn = dynamic_neighbors(role, target=target, k=topn, min_sim=0.03, bias=0.30)\n",
        "    if not dyn:\n",
        "        return pd.DataFrame(columns=[\"dst\",\"score\",\"sim\"])\n",
        "    return pd.DataFrame([(d, s, s) for d, s in dyn], columns=[\"dst\",\"score\",\"sim\"])\n",
        "\n",
        "def best_paths(start: str, goal: str, max_depth: int = 3, beam: int = 6, lam: float = 0.3):\n",
        "    if start == goal:\n",
        "        return [(1.0, [start], [])]\n",
        "    nxt: Dict[str, List[Tuple[str,float]]] = {}\n",
        "    for _, r in EDG.iterrows():\n",
        "        nxt.setdefault(r[\"src\"], []).append((r[\"dst\"], float(r[\"sim\"])))\n",
        "    frontier: List[Tuple[float, List[str], List[float]]] = [(0.0, [start], [])]\n",
        "    best: List[Tuple[float, List[str], List[float]]] = []\n",
        "    for _ in range(max_depth):\n",
        "        new: List[Tuple[float, List[str], List[float]]] = []\n",
        "        for _, nodes, sims in frontier:\n",
        "            cur = nodes[-1]\n",
        "            for dst, sim in sorted(nxt.get(cur, []), key=lambda x: x[1], reverse=True)[:beam]:\n",
        "                if dst in nodes:\n",
        "                    continue\n",
        "                s  = edge_score(cur, dst, sim, lam)\n",
        "                ns = nodes + [dst]\n",
        "                ss = sims + [s]\n",
        "                avg = sum(ss) / len(ss)\n",
        "                if dst == goal:\n",
        "                    best.append((avg, ns, ss))\n",
        "                else:\n",
        "                    new.append((avg, ns, ss))\n",
        "        new.sort(key=lambda x: x[0], reverse=True)\n",
        "        frontier = new[:beam]\n",
        "    best.sort(key=lambda x: x[0], reverse=True)\n",
        "    return best[:3]\n",
        "\n",
        "# -------------------- Explanations & what-if --------------------\n",
        "def explain_step(a: str, b: str, top_k: int = 6):\n",
        "    A = role_skills(a); B = role_skills(b)\n",
        "    carry = sorted(set(A) & set(B), key=lambda s: B[s], reverse=True)[:top_k]\n",
        "    add   = sorted(set(B) - set(A), key=lambda s: B[s], reverse=True)[:top_k]\n",
        "    return carry, add\n",
        "\n",
        "def augment_current_with_skills(cur: str, extra: List[str], default_weight: int = 4) -> Dict[str,int]:\n",
        "    base = role_skills(cur).copy()\n",
        "    for s in extra:\n",
        "        base[s] = max(base.get(s, 0), default_weight)\n",
        "    return base\n",
        "\n",
        "def neighbors_with_added_skills(cur: str, added: List[str], topn: int = 10, lam: float = 0.3):\n",
        "    df_static = EDG[EDG[\"src\"] == cur]\n",
        "    if df_static.empty:\n",
        "        A = augment_current_with_skills(cur, added)\n",
        "        rows = []\n",
        "        for other in ROLES:\n",
        "            if other == cur:\n",
        "                continue\n",
        "            sim_aug = weighted_jaccard(A, _ROLE2SK.get(other, {}))\n",
        "            rows.append((other, sim_aug, sim_aug))\n",
        "        df = pd.DataFrame(rows, columns=[\"dst\",\"score\",\"sim\"])\n",
        "        return df.sort_values(\"score\", ascending=False).head(topn)\n",
        "    A = augment_current_with_skills(cur, added)\n",
        "    rows = []\n",
        "    for _, r in df_static.iterrows():\n",
        "        dst = r[\"dst\"]\n",
        "        sim_aug = weighted_jaccard(A, role_skills(dst))\n",
        "        rows.append((dst, sim_aug * (1 + lam * float(DEM.get(dst, 0.0))), sim_aug))\n",
        "    df = pd.DataFrame(rows, columns=[\"dst\",\"score\",\"sim\"])\n",
        "    return df.sort_values(\"score\", ascending=False).head(topn)\n",
        "\n",
        "# -------------------- Universal dynamic graph --------------------\n",
        "def dynamic_neighbors(role: str,\n",
        "                      target: Optional[str] = None,\n",
        "                      k: int = 25,\n",
        "                      min_sim: float = 0.05,\n",
        "                      bias: float = 0.35) -> List[Tuple[str, float]]:\n",
        "    base = _ROLE2SK.get(role, {})\n",
        "    if not base:\n",
        "        return []\n",
        "    sims: List[Tuple[str, float]] = []\n",
        "    for other, sk in _ROLE2SK.items():\n",
        "        if other == role:\n",
        "            continue\n",
        "        s = weighted_jaccard(base, sk)\n",
        "        if target is not None:\n",
        "            s = s + bias * role_similarity(other, target)\n",
        "        if s >= min_sim:\n",
        "            sims.append((other, float(s)))\n",
        "    sims.sort(key=lambda x: x[1], reverse=True)\n",
        "    return sims[:k]\n",
        "\n",
        "def robust_best_paths(start: str, goal: str, max_depth: int = 4, beam: int = 8,\n",
        "                      k_per_step: int = 25, min_sim: float = 0.05, return_top: int = 3):\n",
        "    if start == goal:\n",
        "        return [(1.0, [start], [])]\n",
        "    def H(r: str) -> float:\n",
        "        return role_similarity(r, goal)\n",
        "    beam_states: List[Tuple[float, float, List[str], List[float]]] = [(H(start), 0.0, [start], [])]\n",
        "    solutions: List[Tuple[float, List[str], List[float]]] = []\n",
        "    for _ in range(max_depth):\n",
        "        new_states: List[Tuple[float, float, List[str], List[float]]] = []\n",
        "        seen = set()\n",
        "        for _, avg_s, path, sims in beam_states:\n",
        "            cur = path[-1]\n",
        "            for nbr, sc in dynamic_neighbors(cur, target=goal, k=k_per_step, min_sim=min_sim, bias=0.35):\n",
        "                if nbr in path:\n",
        "                    continue\n",
        "                sims2 = sims + [sc]\n",
        "                path2 = path + [nbr]\n",
        "                if nbr == goal:\n",
        "                    solutions.append((float(np.mean(sims2)), path2, sims2))\n",
        "                    continue\n",
        "                avg2 = float(np.mean(sims2))\n",
        "                pr   = avg2 + 0.5 * H(nbr)\n",
        "                key  = (nbr, len(path2))\n",
        "                if key in seen: continue\n",
        "                seen.add(key)\n",
        "                new_states.append((pr, avg2, path2, sims2))\n",
        "        if solutions: break\n",
        "        if not new_states: min_sim = max(0.01, min_sim * 0.7)\n",
        "        new_states.sort(key=lambda x: x[0], reverse=True)\n",
        "        beam_states = new_states[:beam]\n",
        "    if solutions:\n",
        "        solutions.sort(key=lambda x: x[0], reverse=True)\n",
        "        return solutions[:return_top]\n",
        "    # Greedy backup\n",
        "    cur = start; path = [cur]; sims: List[float] = []\n",
        "    for _ in range(max_depth):\n",
        "        neigh = dynamic_neighbors(cur, target=goal, k=k_per_step, min_sim=0.01, bias=0.45)\n",
        "        neigh = [n for n in neigh if n[0] not in path]\n",
        "        if not neigh: break\n",
        "        nxt, sc = neigh[0]\n",
        "        path.append(nxt); sims.append(sc); cur = nxt\n",
        "        if cur == goal: break\n",
        "    if path[-1] != goal:\n",
        "        sc = max(0.01, role_similarity(path[-1], goal) * 0.8)\n",
        "        path.append(goal); sims.append(sc)\n",
        "    return [(float(np.mean(sims)) if sims else 0.0, path, sims)]\n",
        "\n",
        "# -------------------- Unified path API --------------------\n",
        "def get_paths(start: str, goal: str,\n",
        "              static_depth: int = 3, static_beam: int = 6,\n",
        "              dyn_depth: int = 4, dyn_beam: int = 10) -> List[Tuple[float, List[str], List[float]]]:\n",
        "    paths = best_paths(start, goal, max_depth=static_depth, beam=static_beam)\n",
        "    if paths: return paths\n",
        "    return robust_best_paths(start, goal, max_depth=dyn_depth, beam=dyn_beam, k_per_step=30, min_sim=0.05)\n",
        "\n",
        "# -------------------- Résumé parsing --------------------\n",
        "def _read_pdf_bytes(b: bytes) -> str:\n",
        "    try:\n",
        "        reader = PdfReader(io.BytesIO(b))\n",
        "        return \"\\n\".join((p.extract_text() or \"\") for p in reader.pages)\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def _read_docx_bytes(b: bytes) -> str:\n",
        "    try:\n",
        "        doc = Document(io.BytesIO(b))\n",
        "        return \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def parse_resume(uploaded_file, pasted_text: str = \"\") -> str:\n",
        "    if uploaded_file is not None:\n",
        "        name = (uploaded_file.name or \"\").lower()\n",
        "        data = uploaded_file.read()\n",
        "        if name.endswith(\".pdf\"):\n",
        "            txt = _read_pdf_bytes(data);  return txt.strip() if txt.strip() else \"\"\n",
        "        elif name.endswith(\".docx\"):\n",
        "            txt = _read_docx_bytes(data); return txt.strip() if txt.strip() else \"\"\n",
        "        elif name.endswith(\".txt\"):\n",
        "            try: return data.decode(\"utf-8\", errors=\"ignore\").strip()\n",
        "            except Exception: pass\n",
        "    return (pasted_text or \"\").strip()\n",
        "\n",
        "# ---------- Skill extraction ----------\n",
        "_SKILL_PAT = { s: re.compile(rf\"\\b{re.escape(s.lower())}\\b\") for s in SKILLS }\n",
        "_ALIASES = { \"sklearn\":\"Scikit-learn\",\"tf\":\"TensorFlow\",\"pytorch\":\"PyTorch\",\"mlops\":\"ML Ops\",\"ml ops\":\"ML Ops\",\"bi\":\"Power BI\",\n",
        "             \"postgres\":\"PostgreSQL\",\"gcp\":\"GCP\",\"aws\":\"AWS\",\"ms sql\":\"SQL\" }\n",
        "\n",
        "def extract_resume_skills(text: str) -> list[str]:\n",
        "    if not text: return []\n",
        "    t = text.lower(); hits = set()\n",
        "    for s, rx in _SKILL_PAT.items():\n",
        "        if s.lower() in t and rx.search(t): hits.add(s)\n",
        "    for alias, canon in _ALIASES.items():\n",
        "        if alias in t and canon in SKILLS: hits.add(canon)\n",
        "    return sorted(hits)\n",
        "\n",
        "# ---------- Role suggestion ----------\n",
        "_ROLE_TOTAL = RS.groupby(\"role\")[\"weight\"].sum().to_dict()\n",
        "\n",
        "def score_roles_by_resume(text: str, topn: int = 8, temperature: float = 0.7):\n",
        "    import numpy as _np\n",
        "    found = set(extract_resume_skills(text))\n",
        "    if not found: return []\n",
        "    rows = []\n",
        "    for role, g in RS.groupby(\"role\"):\n",
        "        skills = {r.skill: int(r.weight) for r in g.itertuples(index=False)}\n",
        "        overlap = [s for s in skills if s in found]\n",
        "        if not overlap: continue\n",
        "        numer = sum(skills[s] for s in overlap)\n",
        "        denom = max(1, int(_ROLE_TOTAL.get(role, 1)))\n",
        "        score = numer / denom\n",
        "        rows.append((role, score, overlap))\n",
        "    if not rows: return []\n",
        "    scores = _np.array([r[1] for r in rows], dtype=float)\n",
        "    logits = scores / max(1e-6, float(temperature))\n",
        "    e = _np.exp(logits - logits.max()); probs = e / e.sum()\n",
        "    ranked = sorted(\n",
        "        [{\"role\": role, \"prob\": float(p), \"score\": float(sc), \"matched_skills\": overlaps}\n",
        "         for (role, sc, overlaps), p in zip(rows, probs)],\n",
        "        key=lambda x: x[\"prob\"], reverse=True\n",
        "    )[:topn]\n",
        "    return ranked\n",
        "\n",
        "__all__ = [\"ROLES\",\"SKILLS\",\"neighbors\",\"best_paths\",\"explain_step\",\"augment_current_with_skills\",\n",
        "           \"neighbors_with_added_skills\",\"get_paths\",\"role_similarity\",\"weighted_jaccard\",\"_ROLE2SK\",\n",
        "           \"role_skills\",\"parse_resume\",\"extract_resume_skills\",\"score_roles_by_resume\"]\n",
        "# utils/__init__.py\n",
        "\n",
        "# Minimal learning links (extend freely)\n",
        "_SKILL_LINKS = {\n",
        "    \"SQL\": [\n",
        "        {\"kind\": \"Tutorial\", \"label\": \"Mode SQL School\", \"url\": \"https://mode.com/sql-tutorial/\"},\n",
        "        {\"kind\": \"Course\", \"label\": \"Khan Academy SQL\", \"url\": \"https://www.khanacademy.org/computing/computer-programming/sql\"}\n",
        "    ],\n",
        "    \"Python\": [\n",
        "        {\"kind\": \"Docs\", \"label\": \"Official Python Tutorial\", \"url\": \"https://docs.python.org/3/tutorial/\"},\n",
        "        {\"kind\": \"Guide\", \"label\": \"Python.org Getting Started\", \"url\": \"https://www.python.org/about/gettingstarted/\"}\n",
        "    ],\n",
        "    \"Machine Learning\": [\n",
        "        {\"kind\": \"Docs\", \"label\": \"scikit-learn Tutorial\", \"url\": \"https://scikit-learn.org/stable/tutorial/index.html\"},\n",
        "        {\"kind\": \"Course\", \"label\": \"Coursera: Andrew Ng ML\", \"url\": \"https://www.coursera.org/learn/machine-learning\"}\n",
        "    ],\n",
        "    \"Pandas\": [\n",
        "        {\"kind\": \"Docs\", \"label\": \"Pandas User Guide\", \"url\": \"https://pandas.pydata.org/docs/user_guide/index.html\"}\n",
        "    ],\n",
        "    \"NumPy\": [\n",
        "        {\"kind\": \"Docs\", \"label\": \"NumPy Learn\", \"url\": \"https://numpy.org/learn/\"}\n",
        "    ],\n",
        "    \"Scikit-learn\": [\n",
        "        {\"kind\": \"Docs\", \"label\": \"scikit-learn User Guide\", \"url\": \"https://scikit-learn.org/stable/user_guide.html\"}\n",
        "    ],\n",
        "    \"TensorFlow\": [\n",
        "        {\"kind\": \"Docs\", \"label\": \"TensorFlow Guide\", \"url\": \"https://www.tensorflow.org/guide\"}\n",
        "    ],\n",
        "    \"Experiment Design\": [\n",
        "        {\"kind\": \"Intro\", \"label\": \"A/B Testing basics\", \"url\": \"https://www.optimizely.com/optimization-glossary/ab-testing/\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "def get_learning_links(skills, max_per_skill=2, max_total=12):\n",
        "    \"\"\"\n",
        "    Return up to max_total learning links across given skills.\n",
        "    Each item will have: {\"skill\": str, \"label\": str, \"url\": str, \"kind\": str}\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for s in skills:\n",
        "        if s in _SKILL_LINKS:\n",
        "            for item in _SKILL_LINKS[s][:max_per_skill]:\n",
        "                out.append({\n",
        "                    \"skill\": s,\n",
        "                    \"label\": item[\"label\"],\n",
        "                    \"url\": item[\"url\"],\n",
        "                    \"kind\": item[\"kind\"],\n",
        "                })\n",
        "                if len(out) >= max_total:\n",
        "                    return out\n",
        "    return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Q94pr2xukv",
        "outputId": "b10d7f53-72af-427d-eb82-8fbae83e373b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import streamlit as st\n",
        "import streamlit.components.v1 as components\n",
        "import re\n",
        "\n",
        "from utils import (\n",
        "    ROLES, SKILLS,\n",
        "    neighbors, explain_step, neighbors_with_added_skills,\n",
        "    get_paths, augment_current_with_skills, role_similarity,\n",
        "    weighted_jaccard, _ROLE2SK, role_skills,\n",
        "    # résumé helpers we added earlier\n",
        "    parse_resume, score_roles_by_resume, extract_resume_skills,\n",
        "    get_learning_links\n",
        ")\n",
        "\n",
        "# ---------- Page + tiny CSS ----------\n",
        "st.set_page_config(page_title=\"nSpire AI · Career Path Simulator\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".path-card {\n",
        "  opacity:0; transform:translateY(12px);\n",
        "  transition:opacity .55s, transform .55s, box-shadow .35s;\n",
        "  border-radius:16px; background:#fff; border:1px solid #e5e7eb;\n",
        "  box-shadow:0 1px 10px rgba(16,24,40,.06); padding:16px 18px; margin-bottom:20px;\n",
        "}\n",
        ".path-card.revealed{opacity:1; transform:translateY(0);\n",
        "  box-shadow:0 18px 40px -12px rgba(37,99,235,.16), 0 4px 16px rgba(16,24,40,.06);\n",
        "}\n",
        ".kpi{display:inline-flex; align-items:center; gap:.55rem; padding:.45rem .7rem;\n",
        "  border-radius:12px; background:#f8fafc; border:1px solid #e5e7eb; font-size:13px;}\n",
        ".skills-box{text-align:center; margin-top:8px;}\n",
        ".badge{display:inline-flex; justify-content:center; align-items:center; padding:8px 14px; margin:6px;\n",
        "  border-radius:999px; font-size:13px; font-weight:600;}\n",
        ".badge.strength{background:#FEF3C7; color:#92400E;}\n",
        ".badge.unlock{background:#D1FAE5; color:#065F46;}\n",
        ".badge.detect{background:#E0E7FF; color:#3730A3;}\n",
        ".mono{font-family:ui-monospace, Menlo, Monaco, Consolas, \"Liberation Mono\"; color:#475569; font-size:12px;}\n",
        ".section-sub{font-weight:700; margin:8px 0 6px; text-align:center;}\n",
        "/* hover help chips */\n",
        ".helpline{font-size:12px; color:#475569; margin:.25rem 0 0 .25rem}\n",
        ".helpchip{display:inline-block; padding:2px 8px; border-radius:10px; border:1px dashed #cbd5e1;\n",
        "  margin-right:6px; cursor:help;}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def reveal_observer():\n",
        "    components.html(\"\"\"\n",
        "    <script>\n",
        "    const attachObserver = () => {\n",
        "      const els = document.querySelectorAll('.path-card:not(.bound)');\n",
        "      if (!('IntersectionObserver' in window)) { els.forEach(el => el.classList.add('revealed')); return; }\n",
        "      const io = new IntersectionObserver((entries) => {\n",
        "        entries.forEach(e => { if (e.isIntersecting) e.target.classList.add('revealed'); });\n",
        "      }, {threshold:.2});\n",
        "      els.forEach(el => { el.classList.add('bound'); io.observe(el); });\n",
        "    };\n",
        "    attachObserver(); setTimeout(attachObserver, 450);\n",
        "    </script>\n",
        "    \"\"\", height=0)\n",
        "\n",
        "# ---------- Small helpers ----------\n",
        "def strength_label(avg: float) -> str:\n",
        "    if avg >= 0.55:  return \"Path Strength: ⭐⭐⭐⭐ Very strong\"\n",
        "    if avg >= 0.40:  return \"Path Strength: ⭐⭐⭐ Strong\"\n",
        "    if avg >= 0.28:  return \"Path Strength: ⭐⭐ Moderate\"\n",
        "    return \"Path Strength: ⭐ Early signal\"\n",
        "\n",
        "def human_overlap_label(sim: float) -> str:\n",
        "    if sim >= 0.55: return \"Easy (high overlap)\"\n",
        "    if sim >= 0.40: return \"Moderate\"\n",
        "    if sim >= 0.25: return \"Stretch\"\n",
        "    return \"Heavy lift\"\n",
        "\n",
        "def stepper_diagram(nodes, sims):\n",
        "    import math\n",
        "\n",
        "    n = len(nodes)\n",
        "    x_mid = 0.5\n",
        "    y_margin = 0.06\n",
        "    char_width = 0.018  # approximate width per character horizontally for box sizing\n",
        "\n",
        "    # Compute box widths based on label lengths\n",
        "    label_lengths = [len(label) for label in nodes]\n",
        "    box_ws = [min(0.36, max(0.19, length * char_width)) for length in label_lengths]\n",
        "\n",
        "    # Fixed box height (vertical spacing)\n",
        "    char_height = 0.06  # approximate height per line (adjust as needed)\n",
        "    box_h = 0.20\n",
        "    half_h = box_h / 2\n",
        "\n",
        "    # Placement: nodes stacked vertically with fixed gap\n",
        "    gap = 0.14  # vertical gap between boxes (adjust as needed)\n",
        "    ys = [1 - y_margin]  # Start top at 1 - margin\n",
        "    for i in range(1, n):\n",
        "        prev_bottom = ys[-1] - box_h\n",
        "        this_top = prev_bottom - gap + box_h  # shift down for next box top\n",
        "        ys.append(this_top - box_h)\n",
        "\n",
        "    # Normalize vertical positions to fit between margins [y_margin, 1 - y_margin]\n",
        "    min_y, max_y = min(ys), max(ys)\n",
        "    desired_min, desired_max = y_margin, 1 - y_margin\n",
        "    scale = (desired_max - desired_min) / (max_y - min_y or 1)\n",
        "    ys = [desired_min + (y - min_y) * scale for y in ys]\n",
        "\n",
        "    node_colors = [\"#2563EB\"] + [\"#14B8A6\"] * (n - 2) + [\"#22C55E\"]\n",
        "    arrow_color = \"rgba(148,163,184,0.55)\"\n",
        "    shapes, ann = [], []\n",
        "    for i, (cy, label, box_w) in enumerate(zip(ys, nodes, box_ws)):\n",
        "        x0, x1 = x_mid - box_w / 2, x_mid + box_w / 2\n",
        "        y0, y1 = cy - half_h, cy + half_h\n",
        "        shapes.append(dict(type=\"rect\", x0=x0, y0=y0, x1=x1, y1=y1,\n",
        "                           line=dict(color=\"rgba(0,0,0,0)\", width=0), fillcolor=node_colors[i], layer=\"below\"))\n",
        "        ann.append(dict(\n",
        "            x=x_mid, y=cy, text=f\"<b>{label}</b>\",\n",
        "            showarrow=False, font=dict(color=\"white\", size=16), xanchor=\"center\", yanchor=\"middle\"\n",
        "        ))\n",
        "\n",
        "    # Draw arrows downward from one box to next\n",
        "    for i in range(n - 1):\n",
        "        x_start = x_mid\n",
        "        y_start = ys[i] - half_h\n",
        "        y_end = ys[i + 1] + half_h\n",
        "\n",
        "        shapes.append(dict(type=\"path\", path=f\"M {x_start} {y_start} L {x_start} {y_end}\",\n",
        "                           line=dict(color=arrow_color, width=10), layer=\"below\"))\n",
        "        # Arrowhead\n",
        "        shapes.append(dict(type=\"path\",\n",
        "                           path=f\"M {x_start - 0.012} {y_end + 0.022} L {x_start} {y_end} L {x_start + 0.012} {y_end + 0.022} Z\",\n",
        "                           fillcolor=arrow_color, line=dict(color=arrow_color), layer=\"above\"))\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.update_layout(\n",
        "        height=400,\n",
        "        margin=dict(l=10, r=10, t=10, b=10),\n",
        "        xaxis=dict(visible=False, range=[0, 1]),\n",
        "        yaxis=dict(visible=False, range=[0, 1], autorange=\"reversed\"),\n",
        "        shapes=shapes,\n",
        "        annotations=ann,\n",
        "        paper_bgcolor=\"white\",\n",
        "        plot_bgcolor=\"white\"\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "def render_skill_group(title: str, items: list[str], kind: str):\n",
        "    st.markdown(f'<div class=\"section-sub\">{title}</div>', unsafe_allow_html=True)\n",
        "    if not items:\n",
        "        st.markdown('<div class=\"skills-box\">—</div>', unsafe_allow_html=True)\n",
        "        return\n",
        "    chips = \" \".join([f'<span class=\"badge {kind}\">{s}</span>' for s in items])\n",
        "    st.markdown(f\"\"\"<div class=\"skills-box\">{chips}</div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def render_learning_links(unlock_skills: list[str]):\n",
        "    links = get_learning_links(unlock_skills, max_per_skill=2, max_total=12)\n",
        "    if not links:\n",
        "        return\n",
        "    st.markdown(\"###### Where to learn next\")\n",
        "    by_skill = {}\n",
        "    for item in links:\n",
        "        by_skill.setdefault(item[\"skill\"], []).append(item)\n",
        "    for skill, items in by_skill.items():\n",
        "        st.markdown(f\"- **{skill}**\")\n",
        "        for it in items:\n",
        "            st.markdown(f'  - {it[\"kind\"]} [{it[\"label\"]}]({it[\"url\"]})')\n",
        "\n",
        "def helpline(*chips):\n",
        "    # chips: list of tuples (label, title)\n",
        "    spans = \" \".join([f'<span class=\"helpchip\" title=\"{t}\">ⓘ {l}</span>' for (l,t) in chips])\n",
        "    st.markdown(f'<div class=\"helpline\">{spans}</div>', unsafe_allow_html=True)\n",
        "\n",
        "# ---------- Session defaults (no yellow warnings) ----------\n",
        "if \"current_prefill\" not in st.session_state:\n",
        "    st.session_state[\"current_prefill\"] = None\n",
        "if \"resume_skills\" not in st.session_state:\n",
        "    st.session_state[\"resume_skills\"] = []\n",
        "if \"sandbox_skills_store\" not in st.session_state:\n",
        "    st.session_state[\"sandbox_skills_store\"] = []  # the source of truth for the multiselect default\n",
        "\n",
        "# ---------- Résumé block ----------\n",
        "st.title(\"Career Path Simulator (Synthetic Data)\")\n",
        "\n",
        "with st.expander(\"Add your résumé (optional)\", expanded=False):\n",
        "    c1, c2 = st.columns([1.25, 1])\n",
        "    with c1:\n",
        "        up = st.file_uploader(\"Upload PDF / DOCX / TXT\", type=[\"pdf\", \"docx\", \"txt\"])\n",
        "        pasted = st.text_area(\"…or paste plain text\", height=160, placeholder=\"Paste your résumé text here\")\n",
        "        resume_text = parse_resume(up, pasted)\n",
        "        if up:\n",
        "            st.caption(f\"Parsed **{up.name}**\")\n",
        "\n",
        "    with c2:\n",
        "        if resume_text:\n",
        "            detected = extract_resume_skills(resume_text)\n",
        "            st.session_state[\"resume_skills\"] = detected[:]  # keep around for the button below\n",
        "            render_skill_group(\"Skills detected in résumé · \" + str(len(detected)), detected, \"detect\")\n",
        "\n",
        "            ranked = score_roles_by_resume(resume_text, topn=8)\n",
        "            if ranked:\n",
        "                df = pd.DataFrame(\n",
        "                    [(r[\"role\"], f\"{r['prob']*100:.1f}%\", f\"{r['score']:.2f}\", len(r[\"matched_skills\"])) for r in ranked],\n",
        "                    columns=[\"Suggested role\", \"Likelihood\", \"Match score (0–1)\", \"Matched skills (#)\"]\n",
        "                )\n",
        "                df.index = np.arange(1, len(df) + 1)  # start at 1\n",
        "                st.dataframe(df, use_container_width=True, height=300)\n",
        "\n",
        "                helpline(\n",
        "                    (\"Likelihood\", \"How strong this role looks for you overall, based on the skills found in your résumé.\"),\n",
        "                    (\"Match score\", \"How much of that role’s skill set appears in your résumé (0–1).\")\n",
        "                )\n",
        "\n",
        "                options = [r[\"role\"] for r in ranked]\n",
        "                chosen = st.selectbox(\"Use this as your current role:\", options, index=0)\n",
        "                cbtn1, cbtn2 = st.columns(2)\n",
        "                with cbtn1:\n",
        "                    if st.button(\"Set as Current Role\"):\n",
        "                        st.session_state[\"current_prefill\"] = chosen\n",
        "                        st.success(f\"Current role set to: {chosen}\")\n",
        "\n",
        "            else:\n",
        "                st.info(\"Couldn’t find clear role matches in the résumé. You can still pick roles manually below.\")\n",
        "        else:\n",
        "            st.caption(\"Upload a résumé or paste text to get automatic suggestions.\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# ---------- Select current/target ----------\n",
        "prefill_role = st.session_state.get(\"current_prefill\")\n",
        "options_current = [\"—\"] + ROLES\n",
        "cur_index = options_current.index(prefill_role) if prefill_role in options_current else 0\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    cur = st.selectbox(\"Select your CURRENT role\", options=options_current, index=cur_index)\n",
        "with col2:\n",
        "    tar = st.selectbox(\"Select your TARGET role\", options=[\"—\"] + ROLES)\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# ---------- What-if skills ----------\n",
        "st.subheader(\"What-if: add skills and see how your next steps change\")\n",
        "\n",
        "resume_skills_available = st.session_state.get(\"resume_skills\",[])\n",
        "\n",
        "# The multiselect takes its default from our store (we never set this widget via session_state key → no yellow box)\n",
        "added_skills = st.multiselect(\n",
        "    \"Choose options\",\n",
        "    options=SKILLS,\n",
        "    default=st.session_state[\"sandbox_skills_store\"]\n",
        ")\n",
        "\n",
        "if resume_skills_available:\n",
        "    label = f\"Add skills from résumé ({len(resume_skills_available)} found)\"\n",
        "    if st.button(label, key=\"add_resume_skills_to_sandbox\", disabled=(len(resume_skills_available) == 0)):\n",
        "        merged = sorted(set(st.session_state[\"sandbox_skills_store\"]) | set(resume_skills_available))\n",
        "        st.session_state[\"sandbox_skills_store\"] = merged\n",
        "        st.success(f\"Added {len(resume_skills_available)} skills from résumé. They now appear in the sandbox.\")\n",
        "        st.rerun()\n",
        "\n",
        "# If user edits selection manually, keep the store in sync (safe—no widget key involved)\n",
        "if added_skills != st.session_state[\"sandbox_skills_store\"]:\n",
        "    st.session_state[\"sandbox_skills_store\"] = added_skills[:]\n",
        "\n",
        "# ---------- Next-step suggestions ----------\n",
        "if cur and cur != \"—\":\n",
        "    st.subheader(f\"Top next-step suggestions from **{cur}**\")\n",
        "\n",
        "    if added_skills:\n",
        "        df_next = neighbors_with_added_skills(cur, added_skills, topn=10)\n",
        "    else:\n",
        "        try:\n",
        "            df_next = neighbors(cur, topn=10, target=(tar if tar != \"—\" else None))\n",
        "        except TypeError:\n",
        "            df_next = neighbors(cur, topn=10)\n",
        "\n",
        "    if df_next is None or df_next.empty:\n",
        "        st.info(\"No strong neighbors at the current threshold.\")\n",
        "    else:\n",
        "        show = df_next.copy().sort_values(\"score\", ascending=False)\n",
        "        show[\"Skill fit (0–1)\"] = show[\"sim\"].map(lambda x: f\"{x:.2f}\")\n",
        "        show[\"Market-aware score\"] = show[\"score\"].map(lambda x: f\"{x:.2f}\")\n",
        "        show = show[[\"dst\", \"Market-aware score\", \"Skill fit (0–1)\"]].rename(columns={\"dst\": \"Suggested role\"})\n",
        "        st.dataframe(show, use_container_width=True, height=280, hide_index=True)\n",
        "\n",
        "        helpline(\n",
        "            (\"Market-aware score\", \"Blend of skill fit and current demand for the destination role.\"),\n",
        "            (\"Skill fit\", \"How closely your current skills match that role (0–1).\")\n",
        "        )\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# ---------- Paths ----------\n",
        "if cur and cur != \"—\" and tar and tar != \"—\":\n",
        "    st.subheader(f\"Paths from **{cur}** → **{tar}** 🔁\")\n",
        "\n",
        "    def dynamic_paths_with_added(start, goal, added, max_paths=3):\n",
        "        if start == goal: return [(1.0, [start], [])]\n",
        "        A = augment_current_with_skills(start, added)\n",
        "        direct = weighted_jaccard(A, _ROLE2SK.get(goal, {}))\n",
        "        candidates = []\n",
        "        for r, sk in _ROLE2SK.items():\n",
        "            if r in (start, goal): continue\n",
        "            s = weighted_jaccard(A, sk)\n",
        "            if s > 0.05: candidates.append((r, s))\n",
        "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "        paths=[]\n",
        "        if direct > 0.10: paths.append((direct, [start, goal], [direct]))\n",
        "        for inter, s1 in candidates[:10]:\n",
        "            s2 = role_similarity(inter, goal)\n",
        "            if s2 > 0.05:\n",
        "                paths.append(((s1+s2)/2, [start, inter, goal], [s1, s2]))\n",
        "        paths.sort(key=lambda x:x[0], reverse=True)\n",
        "        return paths[:max_paths]\n",
        "\n",
        "    if added_skills:\n",
        "        paths = dynamic_paths_with_added(cur, tar, added_skills, max_paths=3)\n",
        "        if paths: st.success(\"✨ Paths updated using your added skills.\")\n",
        "    else:\n",
        "        paths = get_paths(cur, tar, static_depth=3, static_beam=6, dyn_depth=4, dyn_beam=10)\n",
        "\n",
        "    if not paths:\n",
        "        st.warning(\"No good path found. Try a nearby target, or add one intermediate step.\")\n",
        "    else:\n",
        "        reveal_observer()\n",
        "        for i, (avg_score, nodes, sims) in enumerate(paths, start=1):\n",
        "\n",
        "\n",
        "            col_left, col_right = st.columns([2, 3])  # Left wider for path diagram, right for details\n",
        "\n",
        "            with col_left:\n",
        "                st.markdown(f\"**Path {i} · {strength_label(avg_score)}**\")\n",
        "                st.caption(\" → \".join(nodes))\n",
        "                steps = len(nodes) - 1\n",
        "                st.markdown(\n",
        "                    f'<div class=\"kpi\"><b>Steps:</b> {steps}&nbsp;&nbsp;·&nbsp;&nbsp;'\n",
        "                    f'<b>Overall Fit:</b> {int(np.clip(avg_score,0,1)*100)}%</div>',\n",
        "                    unsafe_allow_html=True\n",
        "                )\n",
        "                st.plotly_chart(stepper_diagram(nodes, sims), use_container_width=True, config={\"displayModeBar\": False})\n",
        "\n",
        "\n",
        "\n",
        "            with col_right:\n",
        "                st.markdown(\"#### Why this path works (skills view)\")\n",
        "                for j, (a, b, s) in enumerate(zip(nodes[:-1], nodes[1:], sims)):\n",
        "                    st.markdown(f\"**{a} → {b}**  <span class='mono'>· transition strength {s:.2f}</span>\", unsafe_allow_html=True)\n",
        "                    if j == 0 and added_skills:\n",
        "                        A = augment_current_with_skills(a, added_skills)\n",
        "                        B = role_skills(b)\n",
        "                        carry = sorted(set(A)&set(B), key=lambda x: B.get(x,0), reverse=True)[:8]\n",
        "                        add = sorted(set(B)-set(A), key=lambda x: B.get(x,0), reverse=True)[:8]\n",
        "                    else:\n",
        "                        carry, add = explain_step(a, b, top_k=8)\n",
        "                    overlap_pct = int(np.clip(s,0,1)*100)\n",
        "                    st.markdown(\n",
        "                        f\"<div class='stat-row'>\"\n",
        "                        f\"<span class='stat-tag'> Skill overlap: <b>{overlap_pct}%</b></span>\"\n",
        "                        f\"<span class='stat-tag'> Gap to close: <b>{len(add)} new skill{'s' if len(add)!=1 else ''}</b></span>\"\n",
        "                        f\"<span class='stat-tag'> {human_overlap_label(s)}</span>\"\n",
        "                        f\"</div>\", unsafe_allow_html=True\n",
        "                    )\n",
        "                    render_skill_group(\"Transferable strengths\", carry, \"strength\")\n",
        "                    render_skill_group(\"Skills to unlock next\", add, \"unlock\")\n",
        "                    render_learning_links(add)\n",
        "                    if j < len(sims)-1:\n",
        "                        st.markdown(\"<hr style='border:none;height:1px;background:#e5e7eb;margin:12px 0;'>\", unsafe_allow_html=True)\n",
        "\n",
        "                st.markdown(\"---\")  # separator after each path's explanation\n",
        "\n",
        "        if added_skills:\n",
        "            with st.expander(\"📊 Impact of Added Skills\"):\n",
        "                st.markdown(f\"**Added skills:** {', '.join(added_skills)}\")\n",
        "                st.markdown(\"• Path strengths recalculated with your enhanced profile\")\n",
        "                st.markdown(\"• Transferable strengths updated\")\n",
        "                st.markdown(\"• Next-step suggestions reordered by compatibility\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnEbeK9Gxwbi",
        "outputId": "3c2aef60-27d3-47cf-8c24-6fcdb02a2ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop any previous run\n",
        "!pkill -f streamlit || true\n",
        "\n",
        "# start the app\n",
        "!streamlit run app.py --server.port 8501 --server.headless true &>/content/streamlit.log &\n",
        "\n",
        "# lightweight tunnel (Cloudflare)\n",
        "!curl -L -o cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -#\n",
        "!chmod +x cloudflared\n",
        "!./cloudflared tunnel --url http://localhost:8501 --no-autoupdate > cloudflared.log 2>&1 &\n",
        "\n",
        "# fetch the public URL\n",
        "import time, re, pathlib\n",
        "url = None\n",
        "for _ in range(40):\n",
        "    txt = pathlib.Path(\"cloudflared.log\").read_text(errors=\"ignore\")\n",
        "    m = re.search(r\"https://[a-z0-9-]+\\.trycloudflare\\.com\", txt)\n",
        "    if m:\n",
        "        url = m.group(0); break\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"PUBLIC URL:\", url or \"Still starting... check /content/streamlit.log\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkFayfwFxzuf",
        "outputId": "620fc59f-e36f-4a1a-b752-3eb0415e3cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "######################################################################## 100.0%\n",
            "PUBLIC URL: https://skilled-beats-grams-jenny.trycloudflare.com\n"
          ]
        }
      ]
    }
  ]
}